{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3 (b): Adding dropout "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our own convonlutional layer, full connected layerï¼Œ pooling and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nb_params_shape(shape):\n",
    "    nb_params = 1\n",
    "    for dim in shape:\n",
    "        nb_params = nb_params*int(dim)\n",
    "    return nb_params\n",
    "def count_para():\n",
    "    tot_nb_params = 0\n",
    "    for trainable_variable in tf.trainable_variables():\n",
    "        shape = trainable_variable.get_shape()  # e.g [D,F] or [W,H,C]\n",
    "        current_nb_params = get_nb_params_shape(shape)\n",
    "        tot_nb_params = tot_nb_params + current_nb_params\n",
    "    print (\"Total trainable params number:\", tot_nb_params)\n",
    "\n",
    "def conv2d(x, filter_shape, strides, padding, name):\n",
    "    assert padding in ['SAME', 'VALID']\n",
    "    with tf.variable_scope(name):\n",
    "        W_conv = tf.get_variable('w', shape=filter_shape, \n",
    "                                 initializer = tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv = tf.get_variable('b', shape=[filter_shape[-1]], \n",
    "                                 initializer = tf.zeros_initializer())\n",
    "        y_conv = tf.nn.conv2d(x, W_conv, strides=strides, padding=padding)\n",
    "        y_conv_relu = tf.nn.relu(y_conv + b_conv)\n",
    "    return y_conv_relu\n",
    "    \n",
    "\n",
    "def fc(x, in_size, out_size, name, activation=None):\n",
    "    if activation is not None:\n",
    "        assert activation in ['relu', 'sigmoid', 'tanh'], 'Wrong activation function.'\n",
    "    with tf.variable_scope(name):\n",
    "        w = tf.get_variable('w', shape = [in_size, out_size], dtype=tf.float32, \n",
    "                            initializer = tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b = tf.get_variable('b', shape = [out_size], dtype=tf.float32, \n",
    "                            initializer = tf.zeros_initializer())\n",
    "        h_fc = tf.nn.xw_plus_b(x, w, b)\n",
    "        if activation == 'relu':\n",
    "            return tf.nn.relu(h_fc)\n",
    "        elif activation == 'tanh':\n",
    "            return tf.nn.tanh(h_fc)\n",
    "        elif activation == 'sigmoid':\n",
    "            return tf.nn.sigmoid(h_fc)\n",
    "        else:\n",
    "            return h_fc\n",
    "        \n",
    "\n",
    "def max_pooling(x, k_height, k_width, strides_x, strides_y, padding='SAME'):\n",
    "    ksize=[1,k_height, k_width,1]\n",
    "    strides=[1,strides_x, strides_y,1]\n",
    "    h_pool = tf.nn.max_pool(x, ksize, strides, padding)\n",
    "    return h_pool\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('inputs'):\n",
    "    X_ = tf.placeholder(tf.float32, [None, 784])\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "\n",
    "X = tf.reshape(X_, [-1, 28, 28, 1])\n",
    "conv1 = conv2d(X, [5, 5, 1, 32], [1, 1, 1, 1], 'SAME', 'conv1')\n",
    "h_pool1 = max_pooling(conv1, 2, 2, 2, 2)\n",
    "\n",
    "conv2 = conv2d(h_pool1, [5, 5, 32, 64], [1, 1, 1, 1], 'SAME', 'conv2')\n",
    "h_pool2 = max_pooling(conv2, 2, 2, 2, 2)\n",
    "\n",
    "# flatten\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = fc(h_pool2_flat, 7*7*64, 1024, 'fc1', 'relu')\n",
    "\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "h_fc2 = fc(h_fc1_drop, 1024, 10, 'fc2')\n",
    "y_conv = tf.nn.softmax(h_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-c6fc891b1cd8>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/moquan/anaconda3/envs/tensorflow1.8_gpu/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/moquan/anaconda3/envs/tensorflow1.8_gpu/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/moquan/anaconda3/envs/tensorflow1.8_gpu/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/moquan/anaconda3/envs/tensorflow1.8_gpu/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/moquan/anaconda3/envs/tensorflow1.8_gpu/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Total trainable params number: 3274634\n",
      "step 0, training accuracy 0.12\n",
      "step 1000, training accuracy 0.98\n",
      "step 2000, training accuracy 1\n",
      "step 3000, training accuracy 0.98\n",
      "step 4000, training accuracy 1\n",
      "step 5000, training accuracy 1\n",
      "step 6000, training accuracy 0.96\n",
      "step 7000, training accuracy 1\n",
      "test accuracy 0.9898\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "count_para()\n",
    "\n",
    "for i in range(8000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i%1000 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            X_:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={X_: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    X_: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow1.8_gpu]",
   "language": "python",
   "name": "conda-env-tensorflow1.8_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_nb_params_shape(shape):\n",
    "    nb_params = 1\n",
    "    for dim in shape:\n",
    "        nb_params = nb_params*int(dim)\n",
    "    return nb_params\n",
    "def count_para():\n",
    "    tot_nb_params = 0\n",
    "    for trainable_variable in tf.trainable_variables():\n",
    "        shape = trainable_variable.get_shape()  # e.g [D,F] or [W,H,C]\n",
    "        current_nb_params = get_nb_params_shape(shape)\n",
    "        tot_nb_params = tot_nb_params + current_nb_params\n",
    "    print (\"Total trainable params number:\", tot_nb_params)\n",
    "\n",
    "class SoftmaxLayer:\n",
    "    def __init__(self, _input, _input_num, _classes_num):\n",
    "        # weight\n",
    "        self.W = tf.Variable(tf.zeros([_input_num, _classes_num]), dtype=tf.float32)\n",
    "        # bias\n",
    "        self.b = tf.Variable(tf.zeros([_classes_num,]), dtype=tf.float32)\n",
    "        # output\n",
    "        self.output = tf.nn.softmax(tf.matmul(_input, self.W) + self.b)\n",
    "        # prediction\n",
    "        self.y_pred = tf.argmax(self.output, axis=1)\n",
    "\n",
    "    \n",
    "class HiddenLayer:\n",
    "    def __init__(self, _input, _input_num, _output_num, activ_func = tf.nn.sigmoid):\n",
    "        # weight\n",
    "        bound_val = 4.0*np.sqrt(6.0/(_input_num + _output_num))\n",
    "        self.W = tf.Variable(tf.random_uniform([_input_num, _output_num], minval=-bound_val, maxval=bound_val),dtype=tf.float32, name=\"W\")\n",
    "        # bias\n",
    "        self.b = tf.Variable(tf.zeros([_output_num,]), dtype=tf.float32, name=\"b\")\n",
    "        \n",
    "        # output    print(mnist.test.images.shape)\n",
    "        if activ_func is None:\n",
    "            self.output = tf.matmul(_input, self.W) + self.b\n",
    "        else:\n",
    "            self.output = activ_func(tf.matmul(_input, self.W) + self.b)\n",
    "\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, _input, _input_num, _hidden_num, _output_num):\n",
    "        # Set up the model\n",
    "        last_output = _input\n",
    "        last_output_num = _input_num\n",
    "        \n",
    "        self.hiddenlayer = []\n",
    "        for i in range(len(_hidden_num)):\n",
    "            self.hiddenlayer.append( HiddenLayer(last_output, _input_num = last_output_num, _output_num =_hidden_num[i]) )\n",
    "            last_output = self.hiddenlayer[i].output\n",
    "            last_output_num = _hidden_num[i]\n",
    "\n",
    "        \n",
    "        self.outputlayer = SoftmaxLayer(last_output, _input_num=last_output_num, _classes_num=_output_num)\n",
    "        \n",
    "        # prediction\n",
    "        self.y_pred = self.outputlayer.y_pred\n",
    "\n",
    "\n",
    "    def cross_entropy_loss(self, y):\n",
    "        return -tf.reduce_mean(tf.reduce_sum(y * tf.log(self.outputlayer.output), axis=1))\n",
    "\n",
    "    def accuracy(self, y):\n",
    "        correct_pred = tf.equal(self.outputlayer.y_pred, tf.argmax(y, axis=1))\n",
    "        return tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-e252e27b8148>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/moquan/anaconda3/envs/tensorflow1.8_gpu/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/moquan/anaconda3/envs/tensorflow1.8_gpu/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/moquan/anaconda3/envs/tensorflow1.8_gpu/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/moquan/anaconda3/envs/tensorflow1.8_gpu/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/moquan/anaconda3/envs/tensorflow1.8_gpu/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # load mnist dataset\n",
    "    mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "    \n",
    "    # define training param\n",
    "    epochs_num = 100\n",
    "    batch_size = 100\n",
    "    display_step = 10\n",
    "    batch_num = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    \n",
    "    # define input and output placehoders\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "    # create mlp model\n",
    "    multiclass_logistic_regressor = MLP(_input=x, _input_num=784, _hidden_num=[500,250], _output_num=10)\n",
    "    # get loss\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = multiclass_logistic_regressor.cross_entropy_loss(y_)\n",
    "    #tf.summary.scalar('loss', loss)\n",
    "    # accuracy\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = multiclass_logistic_regressor.accuracy(y_)\n",
    "    #tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "    predictor = multiclass_logistic_regressor.y_pred\n",
    "    \n",
    "\n",
    "\n",
    "    #merged = tf.summary.merge_all()\n",
    "    #train_writer = tf.summary.FileWriter('/train',sess.graph)\n",
    "    #train_writer = tf.summary.FileWriter('./log/train',sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (a) GradientDescentOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable params number: 520260\n",
      "Training, step_size =  0.0001\n",
      "Epoch 0: loss: 2.2993230308185924, validation accuacy: 0.11259999871253967\n",
      "Epoch 10: loss: 2.245841017636386, validation accuacy: 0.26739999651908875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d77f01734480>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mthis_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.8_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.8_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.8_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.8_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.8_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.8_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    for lr in [0.0001, 0.001, 0.01, 0.1, ]: \n",
    "        train_op = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(loss)\n",
    "        init = tf.global_variables_initializer()\n",
    "        count_para()\n",
    "        print(\"Training, step_size = \", lr)\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            \n",
    "            fig = plt.figure() \n",
    "            plt.title('SGD  Step Size = '+ str(lr))\n",
    "            x_axis = []\n",
    "            y_axis = []\n",
    "            it = 0\n",
    "            \n",
    "            for epoch in range(epochs_num):\n",
    "                avg_loss = 0.0\n",
    "            \n",
    "                for i in range(batch_num):\n",
    "                    x_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "                    sess.run(train_op, feed_dict={x: x_batch, y_: y_batch})\n",
    "                    this_loss = sess.run(loss, feed_dict={x: x_batch, y_: y_batch}) \n",
    "                    \n",
    "                    avg_loss += this_loss / batch_num\n",
    "                 \n",
    "                    x_axis.append(it)\n",
    "                    y_axis.append(this_loss)\n",
    "                    it+=1\n",
    "\n",
    "                if epoch % display_step == 0:\n",
    "                    val_acc = sess.run(accuracy, feed_dict={x: mnist.validation.images,\n",
    "                                                           y_: mnist.validation.labels})\n",
    "                    print(\"Epoch {0}: loss: {1}, validation accuacy: {2}\".format(epoch, avg_loss, val_acc))\n",
    "           \n",
    "            plt.plot(x_axis, y_axis)\n",
    "            plt.xlabel('iterations')\n",
    "            plt.ylabel('loss')\n",
    "            plt.show()\n",
    "                    \n",
    "            print(\"Test, step_size = \", lr)\n",
    "            test_acc = sess.run(accuracy, feed_dict={x: mnist.test.images,y_: mnist.test.labels})\n",
    "            print(\"Test: accuacy: {0}\".format(test_acc))\n",
    "\n",
    "            print(\"\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# （b) MomentumOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for lr in [0.01, 0.1]:\n",
    "        for momentum in [0.5, 0.9, 0.99]:\n",
    "            train_op = tf.train.MomentumOptimizer(learning_rate=lr, momentum=momentum).minimize(loss)\n",
    "            init = tf.global_variables_initializer()\n",
    "            print(\"Training, step_size = \", lr, \" momentum = \", momentum)\n",
    "            with tf.Session() as sess:\n",
    "                sess.run(init)\n",
    "            \n",
    "                fig = plt.figure() \n",
    "                fig.suptitle('step size = '+ str(lr)+' momentum = '+str(momentum))\n",
    "                x_axis = []\n",
    "                y_axis = []\n",
    "                it = 0\n",
    "            \n",
    "                for epoch in range(epochs_num):\n",
    "                    avg_loss = 0.0\n",
    "            \n",
    "                    for i in range(batch_num):\n",
    "                        x_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "                        sess.run(train_op, feed_dict={x: x_batch, y_: y_batch})\n",
    "                        this_loss = sess.run(loss, feed_dict={x: x_batch, y_: y_batch}) \n",
    "                    \n",
    "                        avg_loss += this_loss / batch_num\n",
    "                 \n",
    "                        x_axis.append(it)\n",
    "                        y_axis.append(this_loss)\n",
    "                        it+=1\n",
    "\n",
    "                    if epoch % display_step == 0:\n",
    "                        val_acc = sess.run(accuracy, feed_dict={x: mnist.validation.images,\n",
    "                                                           y_: mnist.validation.labels})\n",
    "                        print(\"Epoch {0}: loss: {1}, validation accuacy: {2}\".format(epoch, avg_loss, val_acc))\n",
    "           \n",
    "                plt.plot(x_axis, y_axis)\n",
    "                plt.show()\n",
    "                    \n",
    "                print(\"Testing, step_size = \", lr, \" momentum = \", momentum)\n",
    "                test_acc = sess.run(accuracy, feed_dict={x: mnist.test.images,y_: mnist.test.labels})\n",
    "                print(\"Test: accuacy: {0}\".format(test_acc))\n",
    "\n",
    "                print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (c) & (d) AdamOptimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for lr in [0.0001,0.0005, 0.001, 0.002, 0.01, 0.05]: \n",
    "        train_op = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "        init = tf.global_variables_initializer()\n",
    "        print(\"Training, step_size = \", lr)\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            \n",
    "            fig = plt.figure() \n",
    "            plt.title('Adam Optimizer  Step Size = '+ str(lr))\n",
    "\n",
    "            x_axis = []\n",
    "            y_axis = []\n",
    "            it = 0\n",
    "            \n",
    "            for epoch in range(epochs_num):\n",
    "                avg_loss = 0.0\n",
    "            \n",
    "                for i in range(batch_num):\n",
    "                    x_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "                    sess.run(train_op, feed_dict={x: x_batch, y_: y_batch})\n",
    "                    this_loss = sess.run(loss, feed_dict={x: x_batch, y_: y_batch}) \n",
    "                    \n",
    "                    avg_loss += this_loss / batch_num\n",
    "                 \n",
    "                    x_axis.append(it)\n",
    "                    y_axis.append(this_loss)\n",
    "                    it+=1\n",
    "\n",
    "                if epoch % display_step == 0:\n",
    "                    val_acc = sess.run(accuracy, feed_dict={x: mnist.validation.images,\n",
    "                                                           y_: mnist.validation.labels})\n",
    "                    print(\"Epoch {0}: loss: {1}, validation accuacy: {2}\".format(epoch, avg_loss, val_acc))\n",
    "           \n",
    "            plt.plot(x_axis, y_axis)\n",
    "            plt.xlabel('iterations')\n",
    "            plt.ylabel('loss')\n",
    "            plt.show()\n",
    "                    \n",
    "            print(\"Test, step_size = \", lr)\n",
    "            test_acc = sess.run(accuracy, feed_dict={x: mnist.test.images,y_: mnist.test.labels})\n",
    "            print(\"Test: accuacy: {0}\".format(test_acc))\n",
    "\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow1.8_gpu]",
   "language": "python",
   "name": "conda-env-tensorflow1.8_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
